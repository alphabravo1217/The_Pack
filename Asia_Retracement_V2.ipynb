{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alpha's Backtest Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime, time, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "# #####################################################\n",
    "from Asher_Custom_Functions import *\n",
    "# #####################################################\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If adding or removing any asset below in the variable called \"TickerList\", follow the same format\n",
    "you will also need to into \"TickSize\" and add that value as well.  That information can be found on AMP Futures\n",
    "website: https://www.ampfutures.com/trading-info/contract-specifications\n",
    "\n",
    "You will also have to make the same additions/changes to the similar TickerList/TickSize/Profit_per_Tick in the file called \"Asher_Custom_Functions.py\"\n",
    "\n",
    "Also, change the Session_start and Session_end to whatever opening session range you want to research.  However, the code will\n",
    "not work for a range that from 16:00 - 18:00.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Futures assets currently downloaded for\n",
    "TickerList = (\n",
    "    \"CL=F\", \"ES=F\", \"GC=F\", \"HG=F\", \n",
    "    \"M2K=F\", \"MCL=F\", \"MES=F\", \"MGC=F\", \n",
    "    \"MNQ=F\", \"MYM=F\", \"NG=F\", \"NQ=F\", \n",
    "    \"PL=F\", \"RTY=F\", \"SI=F\", \"SIL=F\", \"YM=F\"\n",
    "    )\n",
    "\n",
    "TickSize = {\n",
    "    \"MES=F\" :   0.2500,   \"MYM=F\" :   1.0000,   \"NG=F\"  :   0.0010,   \"MNQ=F\" :   0.2500,\n",
    "    \"ES=F\"  :   0.2500,   \"NQ=F\"  :   0.2500,   \"YM=F\"  :   1.0000,   \"CL=F\"  :   0.0100,\n",
    "    \"MCL=F\" :   0.0100,   \"GC=F\"  :   0.1000,   \"MGC=F\" :   0.1000,   \"RTY=F\" :   0.1000,\n",
    "    \"M2K=F\" :   0.1000,   \"SI=F\"  :   0.0050,   \"PL=F\"  :   0.1000,   \"HG=F\"  :   0.0005,\n",
    "    \"SIL=F\" :   0.0100\n",
    "}\n",
    "\n",
    "Ticks_per_Point = {asset: 1 / ticksize for asset, ticksize in TickSize.items()}\n",
    "results = []\n",
    "Session_start   = '06:45'\n",
    "Session_end     = '06:50'\n",
    "Trading_Day_end = '16:00'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If downloading data from Yahoo Finance, use the code snippet below.  If downloading smaller than daily data, only \n",
    "download in 2 week increments, using the format below.  TickerInterval is the size of the candle.  I would stick with 1 minute data, as\n",
    "all other timeframes can be calculated from that.\n",
    "\n",
    "If already started downloading data, then this snippet will read the file, and add the recent data to it.  You can change the file path of both the read and write functions to wherever your files are located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StartTimeRange = \"2024-09-15\"\n",
    "# EndTimeRange = \"2024-09-21\"\n",
    "# TickerInterval = \"1m\"\n",
    "\n",
    "# for ticker in TickerList:\n",
    "#     df = pd.read_csv(f'The_Pack/Futures Asset Data/1 Minute Timeframe/{ticker.split(\"=\")[0]}.csv', index_col=False)\n",
    "#     data = yf.download(ticker, start=StartTimeRange, end=EndTimeRange, interval=TickerInterval)\n",
    "#     data.reset_index(inplace=True)\n",
    "#     combined = pd.concat([df, data])\n",
    "#     combined.to_csv(f'{ticker.split(\"=\")[0]}.csv', index=False)\n",
    "#     print(ticker)\n",
    "\n",
    "# print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # All Futures assets currently downloaded for\n",
    "# TickerList = (\n",
    "#     \"CL=F\", \"ES=F\", \"GC=F\", \"HG=F\", \n",
    "#     \"M2K=F\", \"MCL=F\", \"MES=F\", \"MGC=F\", \n",
    "#     \"MNQ=F\", \"MYM=F\", \"NG=F\", \"NQ=F\", \n",
    "#     \"PL=F\", \"RTY=F\", \"SI=F\", \"SIL=F\", \"YM=F\"\n",
    "#     )\n",
    "\n",
    "# TickSize = {\n",
    "#     \"MES=F\" :   0.2500,   \"MYM=F\" :   1.0000,   \"NG=F\"  :   0.0010,   \"MNQ=F\" :   0.2500,\n",
    "#     \"ES=F\"  :   0.2500,   \"NQ=F\"  :   0.2500,   \"YM=F\"  :   1.0000,   \"CL=F\"  :   0.0100,\n",
    "#     \"MCL=F\" :   0.0100,   \"GC=F\"  :   0.1000,   \"MGC=F\" :   0.1000,   \"RTY=F\" :   0.1000,\n",
    "#     \"M2K=F\" :   0.1000,   \"SI=F\"  :   0.0050,   \"PL=F\"  :   0.1000,   \"HG=F\"  :   0.0005,\n",
    "#     \"SIL=F\" :   0.0100\n",
    "# }\n",
    "\n",
    "# Ticks_per_Point = {asset: 1 / ticksize for asset, ticksize in TickSize.items()}\n",
    "# results = []\n",
    "# Session_start   = '06:45'\n",
    "# Session_end     = '06:50'\n",
    "# Trading_Day_end = '16:00'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code only reads the data in the folder:\n",
    "    # df = pd.read_csv(f'Futures Asset Data/1 Minute Timeframe/{ticker.split(\"=\")[0]}.csv')\n",
    "    df = pd.read_csv(f'Futures Asset Data/5 Minute Timeframe/{ticker.split(\"=\")[0]}_5min_Data.csv')\n",
    "    # df = pd.read_csv(f'Futures Asset Data/15 Minute Timeframe/{ticker.split(\"=\")[0]}_15min_Data.csv')\n",
    "\n",
    "the '#' sign is used in Python to comment out that line, meaning the code isn't reading it.  You can change the file folder and file names to whatever you have the files saved as.... as long as you name it 'df'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop_start = datetime.now()\n",
    "for ticker in TickerList:\n",
    "    print(ticker)\n",
    "    code_run_time_start = datetime.now()\n",
    "    \n",
    "    # df = pd.read_csv(f'Futures Asset Data/1 Minute Timeframe/{ticker.split(\"=\")[0]}.csv')\n",
    "    df = pd.read_csv(f'Futures Asset Data/5 Minute Timeframe/{ticker.split(\"=\")[0]}_5min_Data.csv')\n",
    "    # df = pd.read_csv(f'Futures Asset Data/15 Minute Timeframe/{ticker.split(\"=\")[0]}_15min_Data.csv')\n",
    "    df = pd.DataFrame(df)\n",
    "    df['Datetime'] = df['Datetime'].str[:19]\n",
    "    df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "    df.set_index('Datetime', inplace=True)\n",
    "    df2 = df.copy()\n",
    "    \n",
    "    \n",
    "    # Filter out rows where 16:00:00 < datetime < 18:00:00\n",
    "    df2= df2[~((df2.index.time > time(16, 0)) & (df2.index.time < time(18, 0)))]\n",
    "    \n",
    "    # Add day of the week directly without creating 'Group'\n",
    "    df2['Day_of_Week'] = df2.index.map(\n",
    "        lambda dt: (dt.date() if dt.time() >= time(18, 0) else dt.date() - timedelta(days=1)).strftime('%A'))\n",
    "    \n",
    "    \n",
    "    # Session_start_obj = pd.to_datetime(Session_start).time()\n",
    "    df2.index = pd.to_datetime(df2.index)\n",
    "    \n",
    "    midnight = time(23, 59, 59)\n",
    "    start_of_day = time(18, 00)\n",
    "    \n",
    "    df2['TRADE DAY'] = df2.apply(lambda row: row.name.date() \n",
    "                                 if start_of_day <= row.name.time() <= midnight \n",
    "                                 else row.name.date() - timedelta(days=1), axis=1)\n",
    "    \n",
    "    \n",
    "    OpenHighLow = Range_HighLow(df2, Session_start, Session_end)\n",
    "    OpenHighLow['Open Session Range'] = Session_start + ' - ' + Session_end\n",
    "    OpenHighLow['Asset'] = ticker\n",
    "    OpenHighLow['Timeframe'] = '5min'\n",
    "    OpenHighLow = OpenHighLow.rename(columns={'Day_of_Week': 'Day of the Week', 'Highest High': 'Open Session High',\n",
    "                                              'Lowest Low': 'Open Session Low', 'Highest High Time': 'Open Session High Time',\n",
    "                                             'Lowest Low Time': 'Open Session Low Time'})\n",
    "    \n",
    "    # Calculations on the Session_Range\n",
    "    OpenHighLow['Initial Range Size ($)'] = OpenHighLow['Open Session High'] - OpenHighLow['Open Session Low']\n",
    "    OpenHighLow['Range Size (ticks)'] = OpenHighLow['Initial Range Size ($)'] / TickSize[ticker]\n",
    "    OpenHighLow['Range Size (points)'] = OpenHighLow['Initial Range Size ($)'] / Ticks_per_Point[ticker]\n",
    "    \n",
    "    \n",
    "    TradingSession_HighLow = Range_HighLow(df2, Session_end, Trading_Day_end)\n",
    "    TradingSession_HighLow = TradingSession_HighLow.drop(columns=['Day_of_Week'])\n",
    "    TradingSession_HighLow['Trade Session Range'] = Session_end + ' - ' + Trading_Day_end\n",
    "    TradingSession_HighLow = TradingSession_HighLow.rename(columns={'Highest High': 'Trade Session High',\n",
    "                                                                    'Lowest Low': 'Trade Session Low',\n",
    "                                                                    'Highest High Time': 'Trade Session High Time',\n",
    "                                                                    'Lowest Low Time': 'Trade Session Low Time'})\n",
    "    \n",
    "    \n",
    "    Sessions_HighLow = pd.merge(OpenHighLow, TradingSession_HighLow, on='Date')\n",
    "    \n",
    "    first_close = First_Close(df2, Session_start, Session_end, Sessions_HighLow)\n",
    "    firstclose = first_close.drop(columns={'Day of the Week'})\n",
    "    combined = pd.merge(Sessions_HighLow, firstclose, on='Date')\n",
    "    \n",
    "    \n",
    "    Opposite_Cross = opposite_cross(df2, Session_start, Session_end, combined)\n",
    "    Opposite_Cross = Opposite_Cross.drop(columns={'Day of the Week'})\n",
    "    combined2 = pd.merge(combined, Opposite_Cross, on='Date')\n",
    "    \n",
    "    final_df = calculate_distributions(combined2, ticker)\n",
    "    final_df = final_df[['Date', 'Day of the Week', 'Win/(Loss)', 'Asset', 'Timeframe', 'Open Session Range',\n",
    "                     'Open Session High', 'Open Session High Time', 'Open Session Low', 'Open Session Low Time',\n",
    "                     'Initial Range Size ($)', 'Range Size (ticks)', 'Range Size (points)', 'Trade Session Range',\n",
    "                     'Trade Session High', 'Trade Session High Time', 'Trade Session Low', 'Trade Session Low Time',\n",
    "                     'First Close Price', 'First Close Time', 'First Candle Close Condition', 'First Fully Close Price',\n",
    "                     'First Fully Close Time', 'First Candle Fully Close Condition', 'Opposite Side Cross Price',\n",
    "                     'Opposite Side Cross Time', 'Opposite Side Cross Condition', 'Max Distribution/Drawdown (points)',\n",
    "                     'Max Distribution (%)', 'Max Distribution/Drawdown (Fully Outside) (points)',\n",
    "                     'Max Distribution (Fully Outside) (%)'\n",
    "                    ]]\n",
    "    \n",
    "    \n",
    "    stats = pd.DataFrame(index=['Asset', 'Timeframe', 'Wins:', 'Losses:', 'Strike Rate:'])\n",
    "    wins = 0\n",
    "    loss = 0\n",
    "    for result in final_df['Win/(Loss)']:\n",
    "        if result == 'Win':\n",
    "            wins += 1\n",
    "        else:\n",
    "            loss += 1\n",
    "\n",
    "    StrikeRate = round((wins / (wins + loss)) * 100, 3)\n",
    "    wins = round(wins, 3)\n",
    "    loss = round(loss, 3)\n",
    "\n",
    "    # Prepare the column name with ticker and Open_range\n",
    "    just_ticker = ticker.split('=')[0]\n",
    "    # timeframe = '1min'\n",
    "    timeframe = '5min'\n",
    "    # timeframe = '15min'\n",
    "    column_name = f'{just_ticker} {Session_start}-{Session_end}'\n",
    "    \n",
    "    # Store the result in a dictionary\n",
    "    results.append(pd.Series([just_ticker, timeframe, wins, loss, StrikeRate], index=stats.index, name=column_name))\n",
    "\n",
    "    # Concatenate all the results at once to avoid fragmentation\n",
    "    stats = pd.concat(results, axis=1)\n",
    "    stats12 = stats.T.reset_index()\n",
    "    \n",
    "    code_run_time_end = datetime.now()\n",
    "    duration = code_run_time_end - code_run_time_start\n",
    "    print('Code Duration: ', duration)\n",
    "\n",
    "# stats12.to_csv(f'Backtest Results/1 Minute Timeframe Results/Stats_1min/SummaryStats_1min_{Session_start}-{Session_end}.csv', index=False)\n",
    "# stats12.to_csv(f'Backtest Results/5 Minute Timeframe Results/Stats_5min/SummaryStats_5min_{Session_start}-{Session_end}.csv', index=False)\n",
    "# stats12.to_csv(f'Backtest Results/15 Minute Timeframe Results/Stats_15min/SummaryStats_15min_{Session_start}-{Session_end}.csv', index=False)\n",
    "print('Done')\n",
    "loop_end = datetime.now()\n",
    "print('Total Run Time: ', loop_end - loop_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have found whatever asset and whatever timeframe you want more granular data from\n",
    "run the code below, and enter the\n",
    "Session_start, Session_end, Trading_Day_end, and ticker in the quotes that you want to see.\n",
    "\n",
    "If you changed the filename or file path in the first bit of code, then you wil need to change it below as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Session_start   = ' '\n",
    "Session_end     = ' '\n",
    "Trading_Day_end = '16:00'\n",
    "ticker = \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ticker)\n",
    "code_run_time_start = datetime.now()\n",
    "\n",
    "# df = pd.read_csv(f'Futures Asset Data/1 Minute Timeframe/{ticker.split(\"=\")[0]}.csv')\n",
    "df = pd.read_csv(f'Futures Asset Data/5 Minute Timeframe/{ticker.split(\"=\")[0]}_5min_Data.csv')\n",
    "# df = pd.read_csv(f'Futures Asset Data/15 Minute Timeframe/{ticker.split(\"=\")[0]}_15min_Data.csv')\n",
    "df = pd.DataFrame(df)\n",
    "df['Datetime'] = df['Datetime'].str[:19]\n",
    "df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "df.set_index('Datetime', inplace=True)\n",
    "df2 = df.copy()\n",
    "\n",
    "\n",
    "# Filter out rows where 16:00:00 < datetime < 18:00:00\n",
    "df2= df2[~((df2.index.time > time(16, 0)) & (df2.index.time < time(18, 0)))]\n",
    "\n",
    "# Add day of the week directly without creating 'Group'\n",
    "df2['Day_of_Week'] = df2.index.map(\n",
    "    lambda dt: (dt.date() if dt.time() >= time(18, 0) else dt.date() - timedelta(days=1)).strftime('%A'))\n",
    "\n",
    "\n",
    "# Session_start_obj = pd.to_datetime(Session_start).time()\n",
    "df2.index = pd.to_datetime(df2.index)\n",
    "\n",
    "midnight = time(23, 59, 59)\n",
    "start_of_day = time(18, 00)\n",
    "\n",
    "df2['TRADE DAY'] = df2.apply(lambda row: row.name.date() \n",
    "                             if start_of_day <= row.name.time() <= midnight \n",
    "                             else row.name.date() - timedelta(days=1), axis=1)\n",
    "\n",
    "\n",
    "OpenHighLow = Range_HighLow(df2, Session_start, Session_end)\n",
    "OpenHighLow['Open Session Range'] = Session_start + ' - ' + Session_end\n",
    "OpenHighLow['Asset'] = ticker\n",
    "OpenHighLow['Timeframe'] = '5min'\n",
    "OpenHighLow = OpenHighLow.rename(columns={'Day_of_Week': 'Day of the Week', 'Highest High': 'Open Session High',\n",
    "                                          'Lowest Low': 'Open Session Low', 'Highest High Time': 'Open Session High Time',\n",
    "                                         'Lowest Low Time': 'Open Session Low Time'})\n",
    "\n",
    "# Calculations on the Session_Range\n",
    "OpenHighLow['Initial Range Size ($)'] = OpenHighLow['Open Session High'] - OpenHighLow['Open Session Low']\n",
    "OpenHighLow['Range Size (ticks)'] = OpenHighLow['Initial Range Size ($)'] / TickSize[ticker]\n",
    "OpenHighLow['Range Size (points)'] = OpenHighLow['Initial Range Size ($)'] / Ticks_per_Point[ticker]\n",
    "\n",
    "\n",
    "TradingSession_HighLow = Range_HighLow(df2, Session_end, Trading_Day_end)\n",
    "TradingSession_HighLow = TradingSession_HighLow.drop(columns=['Day_of_Week'])\n",
    "TradingSession_HighLow['Trade Session Range'] = Session_end + ' - ' + Trading_Day_end\n",
    "TradingSession_HighLow = TradingSession_HighLow.rename(columns={'Highest High': 'Trade Session High',\n",
    "                                                                'Lowest Low': 'Trade Session Low',\n",
    "                                                                'Highest High Time': 'Trade Session High Time',\n",
    "                                                                'Lowest Low Time': 'Trade Session Low Time'})\n",
    "\n",
    "\n",
    "Sessions_HighLow = pd.merge(OpenHighLow, TradingSession_HighLow, on='Date')\n",
    "\n",
    "first_close = First_Close(df2, Session_start, Session_end, Sessions_HighLow)\n",
    "firstclose = first_close.drop(columns={'Day of the Week'})\n",
    "combined = pd.merge(Sessions_HighLow, firstclose, on='Date')\n",
    "\n",
    "\n",
    "Opposite_Cross = opposite_cross(df2, Session_start, Session_end, combined)\n",
    "Opposite_Cross = Opposite_Cross.drop(columns={'Day of the Week'})\n",
    "combined2 = pd.merge(combined, Opposite_Cross, on='Date')\n",
    "\n",
    "final_df = calculate_distributions(combined2, ticker)\n",
    "final_df = final_df[['Date', 'Day of the Week', 'Win/(Loss)', 'Asset', 'Timeframe', 'Open Session Range',\n",
    "                 'Open Session High', 'Open Session High Time', 'Open Session Low', 'Open Session Low Time',\n",
    "                 'Initial Range Size ($)', 'Range Size (ticks)', 'Range Size (points)', 'Trade Session Range',\n",
    "                 'Trade Session High', 'Trade Session High Time', 'Trade Session Low', 'Trade Session Low Time',\n",
    "                 'First Close Price', 'First Close Time', 'First Candle Close Condition', 'First Fully Close Price',\n",
    "                 'First Fully Close Time', 'First Candle Fully Close Condition', 'Opposite Side Cross Price',\n",
    "                 'Opposite Side Cross Time', 'Opposite Side Cross Condition', 'Max Distribution/Drawdown (points)',\n",
    "                 'Max Distribution (%)', 'Max Distribution/Drawdown (Fully Outside) (points)',\n",
    "                 'Max Distribution (Fully Outside) (%)'\n",
    "                ]]\n",
    "# #######################################################################################\n",
    "# #######################################################################################\n",
    "# #######################################################################################\n",
    "                                                                                     ####\n",
    "final_df.to_csv(' ENTER YOUR FILE PATH and FILE NAME HERE.csv', index_col=False)     ####\n",
    "                                                                                     ####\n",
    "# #######################################################################################\n",
    "# #######################################################################################\n",
    "# #######################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to save any of the scatter plots, then you can uncomment the read/write lines.  If you only\n",
    "want to see the scatter plot of the asset you just ran, then uncomment the df2 = final_df line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df2 = pd.read_csv(f'Backtest Results/1 Minute Timeframe Results/{ticker.split('=')[0]}_1min.csv', index_col=False)\n",
    "# df2 = pd.read_csv(f'Backtest Results/5 Minute Timeframe Results/{ticker.split('=')[0]}_5min.csv', index_col=False)\n",
    "# df2 = pd.read_csv(f'Backtest Results/15 Minute Timeframe Results/{ticker.split('=')[0]}_15min.csv', index_col=False)\n",
    "# df2 = final_df\n",
    "\n",
    "plt.scatter(df2.index, df2['Max Distribution (%)'], color='blue', label='Max Distribution (%)')\n",
    "plt.scatter(df2.index, df2['Max Distribution (Fully Outside) (%)'], color='green', label='Max Distribution (Fully Outside) (%)')\n",
    "\n",
    "# Set the y-axis range based on the maximum value from both columns\n",
    "y_max = max(df2['Max Distribution (%)'].max(), df2['Max Distribution (Fully Outside) (%)'].max())\n",
    "plt.ylim(0, y_max)\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Max MAE/Drawdown')\n",
    "# plt.title('Scatter Plot of Two Columns')\n",
    "plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# Save the plot\n",
    "# plt.savefig(f'Backtest Results/1 Minute Timeframe Results/{ticker.split('=')[0]}_1min.png')\n",
    "# plt.savefig(f'Backtest Results/5 Minute Timeframe Results/{ticker.split('=')[0]}_5min.png')\n",
    "# plt.savefig(f'Backtest Results/15 Minute Timeframe Results/{ticker.split('=')[0]}_15min.png')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "plt.clf()\n",
    "print(ticker)\n",
    "# break\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
